{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# import networkx as nx\n",
    "# import pennylane as qml\n",
    "\n",
    "# # -----------------------------\n",
    "# # Synthetic dataset\n",
    "# # -----------------------------\n",
    "# def make_synthetic_ring(N=12, noise_std=0.1, seed=0):\n",
    "#     \"\"\"\n",
    "#     Creates an N-node ring graph.\n",
    "#     First half nodes label=0, second half label=1.\n",
    "#     Features = one-hot label + Gaussian noise.\n",
    "#     \"\"\"\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     G = nx.cycle_graph(N)\n",
    "#     labels = np.zeros(N, dtype=np.int64)\n",
    "#     labels[N // 2:] = 1\n",
    "\n",
    "#     X = np.zeros((N, 2), dtype=np.float32)\n",
    "#     for i in range(N):\n",
    "#         oh = np.array([1.0, 0.0], dtype=np.float32) if labels[i] == 0 else np.array([0.0, 1.0], dtype=np.float32)\n",
    "#         X[i] = oh + rng.normal(0.0, noise_std, size=2).astype(np.float32)\n",
    "\n",
    "#     edges = np.array(list(G.edges()), dtype=np.int64).T\n",
    "#     edges_rev = edges[::-1]\n",
    "#     edge_index = np.concatenate([edges, edges_rev], axis=1)\n",
    "#     return edge_index, X, labels\n",
    "\n",
    "# # -----------------------------\n",
    "# # Quantum Message-Passing Node Classifier\n",
    "# # -----------------------------\n",
    "# class QMessagePassingNodeClassifier(nn.Module):\n",
    "#     def __init__(self, n_nodes, in_feats=2, T=2, seed=0, verbose=False):\n",
    "#         super().__init__()\n",
    "#         self.verbose = verbose\n",
    "#         self.n_nodes = n_nodes\n",
    "#         self.n_qubits_per_node = 1\n",
    "#         self.total_qubits = n_nodes * self.n_qubits_per_node\n",
    "#         self.T = T\n",
    "\n",
    "#         torch.manual_seed(seed)\n",
    "#         np.random.seed(seed)\n",
    "#         random.seed(seed)\n",
    "\n",
    "#         # Classical encoders: feature -> rotation angles\n",
    "#         self.encoders = nn.ModuleList([\n",
    "#             nn.Linear(in_feats, 2) for _ in range(T)\n",
    "#         ])\n",
    "\n",
    "#         # Shared edge phase parameter per layer\n",
    "#         self.edge_phases = nn.ParameterList([\n",
    "#             nn.Parameter(torch.randn(1) * 0.1) for _ in range(T)\n",
    "#         ])\n",
    "\n",
    "#         # Per-node readout head\n",
    "#         self.readout = nn.ModuleList([\n",
    "#             nn.Linear(1 + in_feats, 2) for _ in range(1)\n",
    "#         ])\n",
    "\n",
    "#         # Quantum device\n",
    "#         self.dev = qml.device(\"default.qubit\", wires=self.total_qubits, shots=None)\n",
    "\n",
    "#         @qml.qnode(self.dev, interface=\"torch\", diff_method=\"best\")\n",
    "#         def circuit(x_feat, edge_index, enc_alphas, enc_betas, edge_phi):\n",
    "#             # Encode features\n",
    "#             for i in range(self.n_nodes):\n",
    "#                 qml.RX(enc_alphas[i], wires=i)\n",
    "#                 qml.RY(enc_betas[i], wires=i)\n",
    "\n",
    "#             # Entangle neighbors\n",
    "#             E = edge_index.shape[1]\n",
    "#             for e in range(E):\n",
    "#                 u = int(edge_index[0, e].item())\n",
    "#                 v = int(edge_index[1, e].item())\n",
    "#                 qml.ControlledPhaseShift(edge_phi, wires=[u, v])\n",
    "\n",
    "#             # Mixing\n",
    "#             for i in range(self.n_nodes):\n",
    "#                 qml.Hadamard(wires=i)\n",
    "\n",
    "#             # Per-node measurement\n",
    "#             return [qml.expval(qml.Z(i)) for i in range(self.n_nodes)]\n",
    "\n",
    "#         self._circuit = circuit\n",
    "\n",
    "#     def forward(self, edge_index_torch, x_torch):\n",
    "#         if edge_index_torch.is_cuda:\n",
    "#             edge_index_torch = edge_index_torch.cpu()\n",
    "#         if x_torch.is_cuda:\n",
    "#             x_torch = x_torch.cpu()\n",
    "\n",
    "#         expvals = None\n",
    "#         for t in range(self.T):\n",
    "#             enc = self.encoders[t](x_torch)  # [N,2] float32\n",
    "#             enc_alphas = enc[:, 0]\n",
    "#             enc_betas = enc[:, 1]\n",
    "#             edge_phi = self.edge_phases[t].squeeze()\n",
    "\n",
    "#             # QNode returns float64 — cast to float32\n",
    "#             layer_out = self._circuit(x_torch, edge_index_torch, enc_alphas, enc_betas, edge_phi)\n",
    "#             layer_out = torch.stack(layer_out, dim=0).float()\n",
    "\n",
    "#             expvals = layer_out\n",
    "\n",
    "#         expvals = expvals.unsqueeze(1)  # [N,1]\n",
    "#         readin = torch.cat([expvals, x_torch], dim=1).float()\n",
    "#         logits = self.readout[0](readin)  # [N,2]\n",
    "#         return logits\n",
    "\n",
    "# # -----------------------------\n",
    "# # Train & evaluate\n",
    "# # -----------------------------\n",
    "# def train_and_eval(N=12, T=2, epochs=150, lr=0.05, seed=0, verbose=False):\n",
    "#     edge_index_np, X_np, y_np = make_synthetic_ring(N=N, seed=seed)\n",
    "#     edge_index = torch.from_numpy(edge_index_np).long()\n",
    "#     X = torch.from_numpy(X_np).float()\n",
    "#     y = torch.from_numpy(y_np).long()\n",
    "\n",
    "#     model = QMessagePassingNodeClassifier(n_nodes=N, in_feats=X.shape[1], T=T, seed=seed, verbose=verbose)\n",
    "#     opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     all_idx = np.arange(N)\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     rng.shuffle(all_idx)\n",
    "#     n_train = int(0.7 * N)\n",
    "#     train_idx = torch.from_numpy(all_idx[:n_train])\n",
    "#     val_idx = torch.from_numpy(all_idx[n_train:])\n",
    "\n",
    "#     for ep in range(1, epochs + 1):\n",
    "#         model.train()\n",
    "#         logits = model(edge_index, X)\n",
    "#         loss = F.cross_entropy(logits[train_idx], y[train_idx])\n",
    "\n",
    "#         opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "\n",
    "#         if verbose and (ep % 20 == 0 or ep == 1):\n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 pred = logits.argmax(dim=1)\n",
    "#                 train_acc = (pred[train_idx] == y[train_idx]).float().mean().item()\n",
    "#                 val_acc = (pred[val_idx] == y[val_idx]).float().mean().item()\n",
    "#             print(f\"Epoch {ep:03d}  loss={loss.item():.4f}  train_acc={train_acc:.3f}  val_acc={val_acc:.3f}\")\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         logits = model(edge_index, X)\n",
    "#         pred = logits.argmax(dim=1)\n",
    "#         acc = (pred == y).float().mean().item()\n",
    "\n",
    "#     print(\"\\nSynthetic dataset description:\")\n",
    "#     print(f\"- Nodes: {N}\")\n",
    "#     print(\"- Graph: ring (cycle)\")\n",
    "#     print(\"- Labels: first half=0, second half=1\")\n",
    "#     print(\"- Features: one-hot label + noise\")\n",
    "#     print(\"\\nNode predictions:\")\n",
    "#     for i in range(N):\n",
    "#         print(f\"Node {i:02d}  label={y[i].item()}  pred={pred[i].item()}\")\n",
    "#     print(f\"\\nOverall node accuracy: {acc:.3f}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     _ = train_and_eval(N=12, T=2, epochs=150, lr=0.05, seed=7, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75477eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# import networkx as nx\n",
    "# import pennylane as qml\n",
    "\n",
    "# # =========================================================\n",
    "# # Utilities\n",
    "# # =========================================================\n",
    "\n",
    "# def set_seeds(seed=0):\n",
    "#     torch.manual_seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "\n",
    "# def confusion_matrix(y_true, y_pred, num_classes=2):\n",
    "#     cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "#     for t, p in zip(y_true, y_pred):\n",
    "#         cm[int(t), int(p)] += 1\n",
    "#     return cm\n",
    "\n",
    "# def macro_accuracy(y_true, y_pred, num_classes=2):\n",
    "#     cm = confusion_matrix(y_true, y_pred, num_classes=num_classes)\n",
    "#     per_class = []\n",
    "#     for c in range(num_classes):\n",
    "#         support = cm[c, :].sum()\n",
    "#         correct = cm[c, c]\n",
    "#         acc_c = correct / support if support > 0 else 0.0\n",
    "#         per_class.append(acc_c)\n",
    "#     return float(np.mean(per_class))\n",
    "\n",
    "# def print_confusion(cm):\n",
    "#     num_classes = cm.shape[0]\n",
    "#     print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "#     for i in range(num_classes):\n",
    "#         row = \" \".join(f\"{cm[i, j]:4d}\" for j in range(num_classes))\n",
    "#         print(f\"class {i}: {row}\")\n",
    "\n",
    "# # =========================================================\n",
    "# # Synthetic multi-graph dataset (node classification)\n",
    "# # =========================================================\n",
    "\n",
    "# def make_synthetic_graph(n_min=10, n_max=30, p_range=(0.08, 0.2), q_range=(0.01, 0.08),\n",
    "#                          feat_noise=0.2, weak_signal_scale=0.4, seed=None):\n",
    "#     \"\"\"\n",
    "#     Generate a single synthetic graph:\n",
    "#     - Two communities with intra/inter probs p,q (p>q).\n",
    "#     - Labels: community id (0/1).\n",
    "#     - Features per node: [deg_norm, clustering, weak_signal] + noise\n",
    "#       where weak_signal = +weak_signal_scale for class 1, -weak_signal_scale for class 0, plus noise.\n",
    "#     Returns:\n",
    "#       edge_index [2, E], X [N, 3], y [N]\n",
    "#     \"\"\"\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     N = rng.integers(n_min, n_max + 1)\n",
    "#     n0 = N // 2\n",
    "#     n1 = N - n0\n",
    "\n",
    "#     p = rng.uniform(*p_range)\n",
    "#     q = rng.uniform(*q_range)\n",
    "#     if p < q:\n",
    "#         p, q = q, p\n",
    "\n",
    "#     G = nx.Graph()\n",
    "#     G.add_nodes_from(range(N))\n",
    "#     comm = np.zeros(N, dtype=int)\n",
    "#     comm[n0:] = 1\n",
    "\n",
    "#     for i in range(N):\n",
    "#         for j in range(i + 1, N):\n",
    "#             prob = p if comm[i] == comm[j] else q\n",
    "#             if rng.random() < prob:\n",
    "#                 G.add_edge(i, j)\n",
    "\n",
    "#     edges = np.array(list(G.edges()), dtype=np.int64).T if G.number_of_edges() > 0 else np.zeros((2,0), dtype=np.int64)\n",
    "#     edges_rev = edges[::-1]\n",
    "#     edge_index = np.concatenate([edges, edges_rev], axis=1) if edges.shape[1] > 0 else edges\n",
    "\n",
    "#     y = comm.astype(np.int64)\n",
    "\n",
    "#     degs = np.array([G.degree(i) for i in range(N)], dtype=np.float32)\n",
    "#     deg_norm = (degs / max(1, N - 1)).astype(np.float32)\n",
    "#     clustering = np.array(list(nx.clustering(G).values()), dtype=np.float32)\n",
    "#     weak_signal = np.where(y == 1, +weak_signal_scale, -weak_signal_scale).astype(np.float32)\n",
    "\n",
    "#     noise = rng.normal(0.0, feat_noise, size=(N, 3)).astype(np.float32)\n",
    "#     X = np.stack([deg_norm, clustering, weak_signal], axis=1) + noise\n",
    "\n",
    "#     return edge_index, X.astype(np.float32), y\n",
    "\n",
    "# def make_dataset(num_graphs=30, seed=0, n_min=10, n_max=30):\n",
    "#     set_seeds(seed)\n",
    "#     ds = []\n",
    "#     for g in range(num_graphs):\n",
    "#         edge_index, X, y = make_synthetic_graph(n_min=n_min, n_max=n_max, seed=seed + 1000 + g)\n",
    "#         ds.append(dict(edge_index=edge_index, X=X, y=y))\n",
    "#     return ds\n",
    "\n",
    "# def train_val_test_split_graphs(num_graphs, splits=(0.6, 0.2, 0.2), seed=0):\n",
    "#     idx = np.arange(num_graphs)\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     rng.shuffle(idx)\n",
    "#     n_train = int(splits[0] * num_graphs)\n",
    "#     n_val = int(splits[1] * num_graphs)\n",
    "#     train_idx = idx[:n_train]\n",
    "#     val_idx = idx[n_train:n_train + n_val]\n",
    "#     test_idx = idx[n_train + n_val:]\n",
    "#     return train_idx, val_idx, test_idx\n",
    "\n",
    "# # =========================================================\n",
    "# # Quantum Message-Passing Node Classifier (PennyLane)\n",
    "# # =========================================================\n",
    "\n",
    "# class QMessagePassingNodeClassifier(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Quantum message-passing node classifier (1 qubit/node):\n",
    "#     - T layers: encode (RX/RY) -> edge entanglers (ControlledPhaseShift) -> mixing (H).\n",
    "#     - Per-node readout: expval(Z) -> linear head with original features to logits.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, n_nodes, in_feats=3, T=2, seed=0, verbose=False, use_gpu_qnode=False):\n",
    "#         super().__init__()\n",
    "#         self.verbose = verbose\n",
    "#         self.n_nodes = n_nodes\n",
    "#         self.total_qubits = n_nodes\n",
    "#         self.T = T\n",
    "\n",
    "#         torch.manual_seed(seed)\n",
    "#         np.random.seed(seed)\n",
    "#         random.seed(seed)\n",
    "\n",
    "#         # Classical parts (will be moved to device by .to(device))\n",
    "#         self.encoders = nn.ModuleList([nn.Linear(in_feats, 2) for _ in range(T)])\n",
    "#         self.edge_phases = nn.ParameterList([nn.Parameter(torch.randn(1) * 0.1) for _ in range(T)])\n",
    "#         self.readout = nn.Linear(1 + in_feats, 2)\n",
    "\n",
    "#         # Quantum device (statevector)\n",
    "#         dev_name = \"default.qubit\"\n",
    "#         if use_gpu_qnode:\n",
    "#             dev_name = \"lightning.gpu\"  # requires pennylane-lightning[gpu]\n",
    "#         self.dev = qml.device(dev_name, wires=self.total_qubits, shots=None)\n",
    "\n",
    "#         @qml.qnode(self.dev, interface=\"torch\", diff_method=\"best\")\n",
    "#         def circuit(edge_index, enc_alphas, enc_betas, edge_phi):\n",
    "#             # Encode\n",
    "#             for i in range(self.n_nodes):\n",
    "#                 qml.RX(enc_alphas[i], wires=i)\n",
    "#                 qml.RY(enc_betas[i], wires=i)\n",
    "#             # Edge entanglers\n",
    "#             E = edge_index.shape[1]\n",
    "#             for e in range(E):\n",
    "#                 u = int(edge_index[0, e].item())\n",
    "#                 v = int(edge_index[1, e].item())\n",
    "#                 if u != v:\n",
    "#                     qml.ControlledPhaseShift(edge_phi, wires=[u, v])\n",
    "#             # Mixing\n",
    "#             for i in range(self.n_nodes):\n",
    "#                 qml.Hadamard(wires=i)\n",
    "#             # Readout\n",
    "#             return [qml.expval(qml.Z(i)) for i in range(self.n_nodes)]\n",
    "\n",
    "#         self._circuit = circuit\n",
    "\n",
    "#     def forward(self, edge_index_torch, x_torch):\n",
    "#         \"\"\"\n",
    "#         edge_index_torch: [2, E] long tensor (can be on CUDA); will be cast to CPU for QNode\n",
    "#         x_torch: [N, F] float tensor on model device (CPU/CUDA)\n",
    "#         \"\"\"\n",
    "#         # Model/device context\n",
    "#         model_device = next(self.parameters()).device\n",
    "\n",
    "#         # 1) Run encoders ON MODEL DEVICE (avoid device mismatch)\n",
    "#         # Ensure x is on model device and correct dtype for Linear\n",
    "#         x_model = x_torch.to(model_device).float()\n",
    "\n",
    "#         # We’ll need both the model-device version (for readout concat)\n",
    "#         # and CPU versions of encoder outputs for the QNode.\n",
    "#         last_expvals_cpu = None\n",
    "\n",
    "#         for t in range(self.T):\n",
    "#             enc = self.encoders[t](x_model)           # [N,2] on model_device\n",
    "#             enc_alphas_model = enc[:, 0]              # model_device\n",
    "#             enc_betas_model  = enc[:, 1]              # model_device\n",
    "#             edge_phi_model   = self.edge_phases[t].squeeze()  # model_device\n",
    "\n",
    "#             # 2) Prepare CPU copies for QNode call\n",
    "#             # PennyLane Torch interface is most robust with CPU tensors\n",
    "#             edge_index_cpu = edge_index_torch.detach().to(\"cpu\")\n",
    "#             enc_alphas_cpu = enc_alphas_model.detach().to(\"cpu\")\n",
    "#             enc_betas_cpu  = enc_betas_model.detach().to(\"cpu\")\n",
    "#             edge_phi_cpu   = edge_phi_model.detach().to(\"cpu\")\n",
    "\n",
    "#             # 3) QNode returns list of expvals -> stack and cast to float32\n",
    "#             layer_out = self._circuit(edge_index_cpu, enc_alphas_cpu, enc_betas_cpu, edge_phi_cpu)\n",
    "#             last_expvals_cpu = torch.stack(layer_out, dim=0).float()  # [N] on CPU\n",
    "\n",
    "#         # 4) Move expvals back to model device for readout\n",
    "#         expvals = last_expvals_cpu.to(model_device).unsqueeze(1)  # [N,1] on model_device\n",
    "\n",
    "#         # 5) Concatenate with original features (on model device) and classify\n",
    "#         readin = torch.cat([expvals, x_model], dim=1)   # [N, 1+F]\n",
    "#         logits = self.readout(readin)                   # [N,2] on model_device\n",
    "#         return logits\n",
    "\n",
    "\n",
    "# # =========================================================\n",
    "# # Training/evaluation over graphs (graph-level split; node-level supervision)\n",
    "# # =========================================================\n",
    "\n",
    "# def train_epoch(model, graphs, optimizer, device=\"cpu\"):\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "#     total_nodes = 0\n",
    "#     for g in graphs:\n",
    "#         edge_index = torch.from_numpy(g[\"edge_index\"]).long().to(device)\n",
    "#         X = torch.from_numpy(g[\"X\"]).float().to(device)\n",
    "#         y = torch.from_numpy(g[\"y\"]).long().to(device)\n",
    "\n",
    "#         logits = model(edge_index, X)\n",
    "#         loss = F.cross_entropy(logits, y)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item() * X.shape[0]\n",
    "#         total_nodes += X.shape[0]\n",
    "#     return total_loss / max(1, total_nodes)\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def evaluate(model, graphs, device=\"cpu\"):\n",
    "#     model.eval()\n",
    "#     all_true = []\n",
    "#     all_pred = []\n",
    "#     total_loss = 0.0\n",
    "#     total_nodes = 0\n",
    "\n",
    "#     for g in graphs:\n",
    "#         edge_index = torch.from_numpy(g[\"edge_index\"]).long().to(device)\n",
    "#         X = torch.from_numpy(g[\"X\"]).float().to(device)\n",
    "#         y = torch.from_numpy(g[\"y\"]).long().to(device)\n",
    "\n",
    "#         logits = model(edge_index, X)\n",
    "#         loss = F.cross_entropy(logits, y)\n",
    "\n",
    "#         pred = logits.argmax(dim=1).cpu().numpy()\n",
    "#         all_pred.extend(list(pred))\n",
    "#         all_true.extend(list(y.cpu().numpy()))\n",
    "\n",
    "#         total_loss += loss.item() * X.shape[0]\n",
    "#         total_nodes += X.shape[0]\n",
    "\n",
    "#     avg_loss = total_loss / max(1, total_nodes)\n",
    "#     all_true = np.array(all_true)\n",
    "#     all_pred = np.array(all_pred)\n",
    "#     mac_acc = macro_accuracy(all_true, all_pred, num_classes=2)\n",
    "#     cm = confusion_matrix(all_true, all_pred, num_classes=2)\n",
    "#     return avg_loss, mac_acc, cm, all_true, all_pred\n",
    "\n",
    "# # =========================================================\n",
    "# # Main experiment\n",
    "# # =========================================================\n",
    "\n",
    "# def run_experiment(\n",
    "#     num_graphs=45,\n",
    "#     splits=(0.6, 0.2, 0.2),\n",
    "#     T=2,\n",
    "#     epochs=50,\n",
    "#     lr=0.03,\n",
    "#     seed=42,\n",
    "#     device=\"cpu\",\n",
    "#     use_gpu_qnode=False,\n",
    "#     verbose=True\n",
    "# ):\n",
    "#     set_seeds(seed)\n",
    "\n",
    "#     # To share one quantum circuit across graphs, fix N (qubit count)\n",
    "#     N_fixed = 20\n",
    "#     dataset = []\n",
    "#     for g in range(num_graphs):\n",
    "#         edge_index, X, y = make_synthetic_graph(n_min=N_fixed, n_max=N_fixed, seed=seed + 2000 + g)\n",
    "#         dataset.append(dict(edge_index=edge_index, X=X, y=y))\n",
    "#     train_idx, val_idx, test_idx = train_val_test_split_graphs(num_graphs, splits=splits, seed=seed)\n",
    "#     train_graphs = [dataset[i] for i in train_idx]\n",
    "#     val_graphs   = [dataset[i] for i in val_idx]\n",
    "#     test_graphs  = [dataset[i] for i in test_idx]\n",
    "\n",
    "#     model = QMessagePassingNodeClassifier(\n",
    "#         n_nodes=N_fixed, in_feats=3, T=T, seed=seed, verbose=verbose, use_gpu_qnode=use_gpu_qnode\n",
    "#     ).to(device)\n",
    "#     opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     best_val = (-1.0, None)  # (macro-acc, state_dict)\n",
    "#     for ep in range(1, epochs + 1):\n",
    "#         tr_loss = train_epoch(model, train_graphs, opt, device=device)\n",
    "#         val_loss, val_mac, val_cm, _, _ = evaluate(model, val_graphs, device=device)\n",
    "#         if verbose:\n",
    "#             print(f\"Epoch {ep:03d} | train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | val_macro_acc={val_mac:.3f}\")\n",
    "\n",
    "#         if val_mac > best_val[0]:\n",
    "#             best_val = (val_mac, {k: v.detach().cpu().clone() for k, v in model.state_dict().items()})\n",
    "\n",
    "#     if best_val[1] is not None:\n",
    "#         model.load_state_dict(best_val[1])\n",
    "\n",
    "#     tr_loss, tr_mac, tr_cm, tr_y, tr_pred = evaluate(model, train_graphs, device=device)\n",
    "#     va_loss, va_mac, va_cm, va_y, va_pred = evaluate(model, val_graphs, device=device)\n",
    "#     te_loss, te_mac, te_cm, te_y, te_pred = evaluate(model, test_graphs, device=device)\n",
    "\n",
    "#     print(\"\\nResults:\")\n",
    "#     print(f\"- Train: macro-acc={tr_mac:.3f}, loss={tr_loss:.4f}\")\n",
    "#     print_confusion(tr_cm)\n",
    "#     print(f\"- Val:   macro-acc={va_mac:.3f}, loss={va_loss:.4f}\")\n",
    "#     print_confusion(va_cm)\n",
    "#     print(f\"- Test:  macro-acc={te_mac:.3f}, loss={te_loss:.4f}\")\n",
    "#     print_confusion(te_cm)\n",
    "\n",
    "#     return {\n",
    "#         \"model\": model,\n",
    "#         \"splits\": (train_idx, val_idx, test_idx),\n",
    "#         \"metrics\": {\n",
    "#             \"train\": dict(loss=tr_loss, macro_acc=tr_mac, cm=tr_cm, y=tr_y, pred=tr_pred),\n",
    "#             \"val\":   dict(loss=va_loss, macro_acc=va_mac, cm=va_cm, y=va_y, pred=va_pred),\n",
    "#             \"test\":  dict(loss=te_loss, macro_acc=te_mac, cm=te_cm, y=te_y, pred=te_pred),\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#     # Set use_gpu_qnode=True to run the quantum simulator on GPU (requires pennylane-lightning[gpu])\n",
    "#     results = run_experiment(\n",
    "#         num_graphs=45,\n",
    "#         splits=(0.6, 0.2, 0.2),\n",
    "#         T=2,\n",
    "#         epochs=50,\n",
    "#         lr=0.03,\n",
    "#         seed=42,\n",
    "#         device=device,\n",
    "#         use_gpu_qnode=True,  # set True if you installed a GPU-backed PennyLane device\n",
    "#         verbose=True\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566156e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "# import networkx as nx\n",
    "# import pennylane as qml\n",
    "\n",
    "# # =========================================================\n",
    "# # Utilities\n",
    "# # =========================================================\n",
    "\n",
    "# def set_seeds(seed=0):\n",
    "#     torch.manual_seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "\n",
    "# def confusion_matrix(y_true, y_pred, num_classes=2):\n",
    "#     cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "#     for t, p in zip(y_true, y_pred):\n",
    "#         cm[int(t), int(p)] += 1\n",
    "#     return cm\n",
    "\n",
    "# def macro_accuracy(y_true, y_pred, num_classes=2):\n",
    "#     cm = confusion_matrix(y_true, y_pred, num_classes=num_classes)\n",
    "#     per_class = []\n",
    "#     for c in range(num_classes):\n",
    "#         support = cm[c, :].sum()\n",
    "#         correct = cm[c, c]\n",
    "#         acc_c = correct / support if support > 0 else 0.0\n",
    "#         per_class.append(acc_c)\n",
    "#     return float(np.mean(per_class))\n",
    "\n",
    "# def print_confusion(cm):\n",
    "#     num_classes = cm.shape[0]\n",
    "#     print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "#     for i in range(num_classes):\n",
    "#         row = \" \".join(f\"{cm[i, j]:4d}\" for j in range(num_classes))\n",
    "#         print(f\"class {i}: {row}\")\n",
    "\n",
    "# # =========================================================\n",
    "# # Synthetic multi-graph dataset (node classification)\n",
    "# # =========================================================\n",
    "\n",
    "# def make_synthetic_graph(n_min=10, n_max=30, p_range=(0.08, 0.2), q_range=(0.01, 0.08),\n",
    "#                          feat_noise=0.2, weak_signal_scale=0.4, seed=None):\n",
    "#     \"\"\"\n",
    "#     Generate a single synthetic graph:\n",
    "#     - Two communities with intra/inter probs p,q (p>q).\n",
    "#     - Labels: community id (0/1).\n",
    "#     - Features per node: [deg_norm, clustering, weak_signal] + noise\n",
    "#     \"\"\"\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     N = rng.integers(n_min, n_max + 1)\n",
    "#     n0 = N // 2\n",
    "#     n1 = N - n0\n",
    "\n",
    "#     p = rng.uniform(*p_range)\n",
    "#     q = rng.uniform(*q_range)\n",
    "#     if p < q:\n",
    "#         p, q = q, p\n",
    "\n",
    "#     G = nx.Graph()\n",
    "#     G.add_nodes_from(range(N))\n",
    "#     comm = np.zeros(N, dtype=int)\n",
    "#     comm[n0:] = 1\n",
    "\n",
    "#     for i in range(N):\n",
    "#         for j in range(i + 1, N):\n",
    "#             prob = p if comm[i] == comm[j] else q\n",
    "#             if rng.random() < prob:\n",
    "#                 G.add_edge(i, j)\n",
    "\n",
    "#     edges = np.array(list(G.edges()), dtype=np.int64).T if G.number_of_edges() > 0 else np.zeros((2,0), dtype=np.int64)\n",
    "#     edges_rev = edges[::-1]\n",
    "#     edge_index = np.concatenate([edges, edges_rev], axis=1) if edges.shape[1] > 0 else edges\n",
    "\n",
    "#     y = comm.astype(np.int64)\n",
    "\n",
    "#     degs = np.array([G.degree(i) for i in range(N)], dtype=np.float32)\n",
    "#     deg_norm = (degs / max(1, N - 1)).astype(np.float32)\n",
    "#     clustering = np.array(list(nx.clustering(G).values()), dtype=np.float32)\n",
    "#     weak_signal = np.where(y == 1, +weak_signal_scale, -weak_signal_scale).astype(np.float32)\n",
    "\n",
    "#     noise = rng.normal(0.0, feat_noise, size=(N, 3)).astype(np.float32)\n",
    "#     X = np.stack([deg_norm, clustering, weak_signal], axis=1) + noise\n",
    "\n",
    "#     return edge_index, X.astype(np.float32), y\n",
    "\n",
    "# def make_dataset(num_graphs=30, seed=0, n_min=10, n_max=30):\n",
    "#     set_seeds(seed)\n",
    "#     ds = []\n",
    "#     for g in range(num_graphs):\n",
    "#         edge_index, X, y = make_synthetic_graph(n_min=n_min, n_max=n_max, seed=seed + 1000 + g)\n",
    "#         ds.append(dict(edge_index=edge_index, X=X, y=y))\n",
    "#     return ds\n",
    "\n",
    "# def train_val_test_split_graphs(num_graphs, splits=(0.6, 0.2, 0.2), seed=0):\n",
    "#     idx = np.arange(num_graphs)\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     rng.shuffle(idx)\n",
    "#     n_train = int(splits[0] * num_graphs)\n",
    "#     n_val = int(splits[1] * num_graphs)\n",
    "#     train_idx = idx[:n_train]\n",
    "#     val_idx = idx[n_train:n_train + n_val]\n",
    "#     test_idx = idx[n_train + n_val:]\n",
    "#     return train_idx, val_idx, test_idx\n",
    "\n",
    "# # =========================================================\n",
    "# # EDU-QGC Node Classifier (PennyLane)\n",
    "# # =========================================================\n",
    "\n",
    "# class EDUQGCNodeClassifier(nn.Module):\n",
    "#     \"\"\"\n",
    "#     EDU-QGC-style quantum graph node classifier (1 qubit/node).\n",
    "\n",
    "#     Each of T layers:\n",
    "#       - L_node: shared feature encoder (W,b) -> shared node unitary U_node on every node\n",
    "#       - L_edge: shared two-qubit EDU on every edge:\n",
    "#                 (U_pre ⊗ U_pre) -> CRZ(phi) -> (U_post ⊗ U_post)\n",
    "\n",
    "#     Readout: expval(Z_i) per node -> (optional feat skip) -> shared linear head -> logits.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, n_nodes, in_feats=3, T=2, seed=0, verbose=False, use_gpu_qnode=False):\n",
    "#         super().__init__()\n",
    "#         self.verbose = verbose\n",
    "#         self.n_nodes = n_nodes\n",
    "#         self.T = T\n",
    "#         self.in_feats = in_feats\n",
    "\n",
    "#         torch.manual_seed(seed)\n",
    "#         np.random.seed(seed)\n",
    "#         random.seed(seed)\n",
    "\n",
    "#         # ---------- Shared feature encoders per layer ----------\n",
    "#         # angles_i = X_i @ W^T + b  -> [alpha_i, beta_i]\n",
    "#         self.enc_W = nn.ParameterList([nn.Parameter(torch.randn(2, in_feats) * 0.2) for _ in range(T)])\n",
    "#         self.enc_b = nn.ParameterList([nn.Parameter(torch.zeros(2)) for _ in range(T)])\n",
    "\n",
    "#         # ---------- Shared node unitary per layer ----------\n",
    "#         # U_node = RZ(gamma) RX(delta)  (same for all nodes in the layer)\n",
    "#         self.node_gamma = nn.ParameterList([nn.Parameter(torch.randn(1) * 0.1) for _ in range(T)])\n",
    "#         self.node_delta = nn.ParameterList([nn.Parameter(torch.randn(1) * 0.1) for _ in range(T)])\n",
    "\n",
    "#         # ---------- Shared EDU parameters per layer ----------\n",
    "#         # EDU(u,v) = (U_pre ⊗ U_pre) -> CRZ(phi) -> (U_post ⊗ U_post)\n",
    "#         # U_pre  = RY(theta_pre) RZ(psi_pre)\n",
    "#         # U_post = RZ(psi_post)  RY(theta_post)\n",
    "#         self.edge_phi   = nn.ParameterList([nn.Parameter(torch.randn(1) * 0.1) for _ in range(T)])\n",
    "#         self.pre_theta  = nn.ParameterList([nn.Parameter(torch.randn(1) * 0.1) for _ in range(T)])\n",
    "#         self.pre_psi    = nn.ParameterList([nn.Parameter(torch.randn(1) * 0.1) for _ in range(T)])\n",
    "#         self.post_theta = nn.ParameterList([nn.Parameter(torch.randn(1) * 0.1) for _ in range(T)])\n",
    "#         self.post_psi   = nn.ParameterList([nn.Parameter(torch.randn(1) * 0.1) for _ in range(T)])\n",
    "\n",
    "#         # ---------- Readout ----------\n",
    "#         self.use_feat_skip = True\n",
    "#         readin_dim = 1 + (in_feats if self.use_feat_skip else 0)\n",
    "#         self.readout = nn.Linear(readin_dim, 2)\n",
    "\n",
    "#         # ---------- Quantum device ----------\n",
    "#         dev_name = \"default.qubit\"\n",
    "#         if use_gpu_qnode:\n",
    "#             dev_name = \"lightning.gpu\"  # requires pennylane-lightning[gpu]\n",
    "#         self.dev = qml.device(dev_name, wires=n_nodes, shots=None)\n",
    "\n",
    "#         @qml.qnode(self.dev, interface=\"torch\", diff_method=\"best\")\n",
    "#         def circuit(edge_index, X,\n",
    "#                     enc_W_list, enc_b_list,\n",
    "#                     node_gamma_list, node_delta_list,\n",
    "#                     edge_phi_list, pre_theta_list, pre_psi_list, post_theta_list, post_psi_list):\n",
    "#             \"\"\"\n",
    "#             edge_index: [2, E] (long)\n",
    "#             X: [N, F] (float)\n",
    "#             All parameter lists: torch tensors (on CPU) with gradients.\n",
    "#             \"\"\"\n",
    "#             N = X.shape[0]\n",
    "\n",
    "#             def shared_node_unitary(layer_idx, wire):\n",
    "#                 qml.RZ(node_gamma_list[layer_idx], wires=wire)\n",
    "#                 qml.RX(node_delta_list[layer_idx], wires=wire)\n",
    "\n",
    "#             def U_pre(layer_idx, wire):\n",
    "#                 qml.RY(pre_theta_list[layer_idx], wires=wire)\n",
    "#                 qml.RZ(pre_psi_list[layer_idx], wires=wire)\n",
    "\n",
    "#             def U_post(layer_idx, wire):\n",
    "#                 qml.RZ(post_psi_list[layer_idx], wires=wire)\n",
    "#                 qml.RY(post_theta_list[layer_idx], wires=wire)\n",
    "\n",
    "#             def EDU_edge(layer_idx, u, v):\n",
    "#                 U_pre(layer_idx, u); U_pre(layer_idx, v)\n",
    "#                 qml.CRZ(edge_phi_list[layer_idx], wires=[u, v])\n",
    "#                 U_post(layer_idx, u); U_post(layer_idx, v)\n",
    "\n",
    "#             # Stack T equivariant layers\n",
    "#             for t in range(self.T):\n",
    "#                 # L_node: shared encoder + shared single-qubit unitary\n",
    "#                 W = enc_W_list[t]      # [2, F]\n",
    "#                 b = enc_b_list[t]      # [2]\n",
    "#                 # angles = X @ W^T + b   -> [N,2]\n",
    "#                 angles = qml.math.dot(X, qml.math.transpose(W)) + b\n",
    "\n",
    "#                 for i in range(N):\n",
    "#                     qml.RX(angles[i, 0], wires=i)\n",
    "#                     qml.RY(angles[i, 1], wires=i)\n",
    "#                     shared_node_unitary(t, i)\n",
    "\n",
    "#                 # L_edge: shared EDU on every edge\n",
    "#                 E = edge_index.shape[1]\n",
    "#                 for e in range(E):\n",
    "#                     u = int(edge_index[0, e].item())\n",
    "#                     v = int(edge_index[1, e].item())\n",
    "#                     if u != v:\n",
    "#                         EDU_edge(t, u, v)\n",
    "\n",
    "#             # Nodewise Z-basis readout\n",
    "#             return [qml.expval(qml.Z(i)) for i in range(N)]\n",
    "\n",
    "#         self._circuit = circuit\n",
    "\n",
    "#     def forward(self, edge_index_torch, x_torch):\n",
    "#         \"\"\"\n",
    "#         edge_index_torch: [2, E] long tensor (can be on CUDA); passed to CPU for QNode\n",
    "#         x_torch: [N, F] float tensor\n",
    "#         \"\"\"\n",
    "#         model_device = next(self.parameters()).device\n",
    "#         x_model = x_torch.to(model_device).float()\n",
    "\n",
    "#         # Move data + params to CPU for the QNode WITHOUT detaching (preserve grads)\n",
    "#         edge_index_cpu = edge_index_torch.to(\"cpu\")\n",
    "#         X_cpu = x_model.to(\"cpu\")\n",
    "\n",
    "#         enc_W_list   = [p.to(\"cpu\") for p in self.enc_W]\n",
    "#         enc_b_list   = [p.to(\"cpu\") for p in self.enc_b]\n",
    "#         node_g_list  = [p.to(\"cpu\") for p in self.node_gamma]\n",
    "#         node_d_list  = [p.to(\"cpu\") for p in self.node_delta]\n",
    "#         edge_phi_list  = [p.to(\"cpu\") for p in self.edge_phi]\n",
    "#         pre_th_list    = [p.to(\"cpu\") for p in self.pre_theta]\n",
    "#         pre_psi_list   = [p.to(\"cpu\") for p in self.pre_psi]\n",
    "#         post_th_list   = [p.to(\"cpu\") for p in self.post_theta]\n",
    "#         post_psi_list  = [p.to(\"cpu\") for p in self.post_psi]\n",
    "\n",
    "#         # Run quantum circuit\n",
    "#        # Run quantum circuit\n",
    "#         layer_out = self._circuit(\n",
    "#             edge_index_cpu, X_cpu,\n",
    "#             enc_W_list, enc_b_list,\n",
    "#             node_g_list, node_d_list,\n",
    "#             edge_phi_list, pre_th_list, pre_psi_list, post_th_list, post_psi_list\n",
    "#         )\n",
    "\n",
    "#         # Convert list of expvals → [N,1] tensor\n",
    "#         expvals = torch.stack(layer_out, dim=0).float().to(model_device)  # [N] or [N,1?]\n",
    "#         if expvals.dim() == 1:\n",
    "#             expvals = expvals.unsqueeze(1)        # [N,1]\n",
    "#         elif expvals.dim() == 2 and expvals.shape[1] == 1:\n",
    "#             pass  # already [N,1]\n",
    "#         else:\n",
    "#             expvals = expvals.squeeze(-1).unsqueeze(1)  # force [N,1]\n",
    "\n",
    "#         # Readout\n",
    "#         if self.use_feat_skip:\n",
    "#             readin = torch.cat([expvals, x_model], dim=1)  # [N, 1+F]\n",
    "#         else:\n",
    "#             readin = expvals\n",
    "\n",
    "#         logits = self.readout(readin)                     # [N,2]\n",
    "#         return logits\n",
    "\n",
    "# # =========================================================\n",
    "# # Training/evaluation over graphs (graph-level split; node-level supervision)\n",
    "# # =========================================================\n",
    "\n",
    "# def train_epoch(model, graphs, optimizer, device=\"cpu\"):\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "#     total_nodes = 0\n",
    "#     for g in graphs:\n",
    "#         edge_index = torch.from_numpy(g[\"edge_index\"]).long().to(device)\n",
    "#         X = torch.from_numpy(g[\"X\"]).float().to(device)\n",
    "#         y = torch.from_numpy(g[\"y\"]).long().to(device)\n",
    "\n",
    "#         logits = model(edge_index, X)\n",
    "#         loss = F.cross_entropy(logits, y)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item() * X.shape[0]\n",
    "#         total_nodes += X.shape[0]\n",
    "#     return total_loss / max(1, total_nodes)\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def evaluate(model, graphs, device=\"cpu\"):\n",
    "#     model.eval()\n",
    "#     all_true = []\n",
    "#     all_pred = []\n",
    "#     total_loss = 0.0\n",
    "#     total_nodes = 0\n",
    "\n",
    "#     for g in graphs:\n",
    "#         edge_index = torch.from_numpy(g[\"edge_index\"]).long().to(device)\n",
    "#         X = torch.from_numpy(g[\"X\"]).float().to(device)\n",
    "#         y = torch.from_numpy(g[\"y\"]).long().to(device)\n",
    "\n",
    "#         logits = model(edge_index, X)\n",
    "#         loss = F.cross_entropy(logits, y)\n",
    "\n",
    "#         pred = logits.argmax(dim=1).cpu().numpy()\n",
    "#         all_pred.extend(list(pred))\n",
    "#         all_true.extend(list(y.cpu().numpy()))\n",
    "\n",
    "#         total_loss += loss.item() * X.shape[0]\n",
    "#         total_nodes += X.shape[0]\n",
    "\n",
    "#     avg_loss = total_loss / max(1, total_nodes)\n",
    "#     all_true = np.array(all_true)\n",
    "#     all_pred = np.array(all_pred)\n",
    "#     mac_acc = macro_accuracy(all_true, all_pred, num_classes=2)\n",
    "#     cm = confusion_matrix(all_true, all_pred, num_classes=2)\n",
    "#     return avg_loss, mac_acc, cm, all_true, all_pred\n",
    "\n",
    "# # =========================================================\n",
    "# # Main experiment (same task as before)\n",
    "# # =========================================================\n",
    "\n",
    "# def run_experiment(\n",
    "#     num_graphs=45,\n",
    "#     splits=(0.6, 0.2, 0.2),\n",
    "#     T=2,\n",
    "#     epochs=50,\n",
    "#     lr=0.03,\n",
    "#     seed=42,\n",
    "#     device=\"cpu\",\n",
    "#     use_gpu_qnode=False,\n",
    "#     verbose=True\n",
    "# ):\n",
    "#     set_seeds(seed)\n",
    "\n",
    "#     # Fix N to share the same circuit size across graphs\n",
    "#     N_fixed = 20\n",
    "#     dataset = []\n",
    "#     for g in range(num_graphs):\n",
    "#         edge_index, X, y = make_synthetic_graph(n_min=N_fixed, n_max=N_fixed, seed=seed + 2000 + g)\n",
    "#         dataset.append(dict(edge_index=edge_index, X=X, y=y))\n",
    "#     train_idx, val_idx, test_idx = train_val_test_split_graphs(num_graphs, splits=splits, seed=seed)\n",
    "#     train_graphs = [dataset[i] for i in train_idx]\n",
    "#     val_graphs   = [dataset[i] for i in val_idx]\n",
    "#     test_graphs  = [dataset[i] for i in test_idx]\n",
    "\n",
    "#     model = EDUQGCNodeClassifier(\n",
    "#         n_nodes=N_fixed, in_feats=3, T=T, seed=seed, verbose=verbose, use_gpu_qnode=use_gpu_qnode\n",
    "#     ).to(device)\n",
    "#     opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     best_val = (-1.0, None)  # (macro-acc, state_dict)\n",
    "#     for ep in range(1, epochs + 1):\n",
    "#         tr_loss = train_epoch(model, train_graphs, opt, device=device)\n",
    "#         val_loss, val_mac, val_cm, _, _ = evaluate(model, val_graphs, device=device)\n",
    "#         if verbose:\n",
    "#             print(f\"Epoch {ep:03d} | train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | val_macro_acc={val_mac:.3f}\")\n",
    "\n",
    "#         if val_mac > best_val[0]:\n",
    "#             best_val = (val_mac, {k: v.detach().cpu().clone() for k, v in model.state_dict().items()})\n",
    "\n",
    "#     if best_val[1] is not None:\n",
    "#         model.load_state_dict(best_val[1])\n",
    "\n",
    "#     tr_loss, tr_mac, tr_cm, tr_y, tr_pred = evaluate(model, train_graphs, device=device)\n",
    "#     va_loss, va_mac, va_cm, va_y, va_pred = evaluate(model, val_graphs, device=device)\n",
    "#     te_loss, te_mac, te_cm, te_y, te_pred = evaluate(model, test_graphs, device=device)\n",
    "\n",
    "#     print(\"\\nResults:\")\n",
    "#     print(f\"- Train: macro-acc={tr_mac:.3f}, loss={tr_loss:.4f}\")\n",
    "#     print_confusion(tr_cm)\n",
    "#     print(f\"- Val:   macro-acc={va_mac:.3f}, loss={va_loss:.4f}\")\n",
    "#     print_confusion(va_cm)\n",
    "#     print(f\"- Test:  macro-acc={te_mac:.3f}, loss={te_loss:.4f}\")\n",
    "#     print_confusion(te_cm)\n",
    "\n",
    "#     return {\n",
    "#         \"model\": model,\n",
    "#         \"splits\": (train_idx, val_idx, test_idx),\n",
    "#         \"metrics\": {\n",
    "#             \"train\": dict(loss=tr_loss, macro_acc=tr_mac, cm=tr_cm, y=tr_y, pred=tr_pred),\n",
    "#             \"val\":   dict(loss=va_loss, macro_acc=va_mac, cm=va_cm, y=va_y, pred=va_pred),\n",
    "#             \"test\":  dict(loss=te_loss, macro_acc=te_mac, cm=te_cm, y=te_y, pred=te_pred),\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#     # Set use_gpu_qnode=True to use a GPU-backed PennyLane device if installed (pennylane-lightning[gpu])\n",
    "#     results = run_experiment(\n",
    "#         num_graphs=45,\n",
    "#         splits=(0.6, 0.2, 0.2),\n",
    "#         T=2,\n",
    "#         epochs=50,\n",
    "#         lr=0.03,\n",
    "#         seed=42,\n",
    "#         device=device,\n",
    "#         use_gpu_qnode=True,\n",
    "#         verbose=True\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e4d0c0",
   "metadata": {},
   "source": [
    "#EDU-QGC with Repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edu_qgc_repro_full.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "EDU-QGC Node Classification with strict reproducibility and dataset saving.\n",
    "\n",
    "Run:\n",
    "  python edu_qgc_repro_full.py\n",
    "\n",
    "Requirements:\n",
    "  pip install torch pennylane pennylane-lightning[gpu] networkx matplotlib\n",
    "(If you don't have CUDA or lightning.gpu, the code falls back to default.qubit CPU simulator.)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "# MUST set CUBLAS_WORKSPACE_CONFIG before importing torch to enable deterministic cuBLAS\n",
    "os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\")\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Now import torch after setting env var\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import networkx as nx\n",
    "import pennylane as qml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# Reproducibility helper\n",
    "# ---------------------------\n",
    "def set_global_determinism(seed: int):\n",
    "    \"\"\"\n",
    "    Set seeds and flags to make experiments deterministic where feasible.\n",
    "    Must set CUBLAS_WORKSPACE_CONFIG BEFORE importing torch (done at top).\n",
    "    \"\"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Enable deterministic algorithms (will raise if impossible)\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception as e:\n",
    "        # Give clear advice and re-raise\n",
    "        print(\"Failed to enable deterministic algorithms:\", e)\n",
    "        print(\"Make sure CUBLAS_WORKSPACE_CONFIG is set before Python starts.\")\n",
    "        print(\"If running in Jupyter, restart the kernel after setting the env var.\")\n",
    "        raise\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def confusion_matrix(y_true, y_pred, num_classes=2):\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[int(t), int(p)] += 1\n",
    "    return cm\n",
    "\n",
    "def macro_accuracy(y_true, y_pred, num_classes=2):\n",
    "    cm = confusion_matrix(y_true, y_pred, num_classes=num_classes)\n",
    "    per_class = []\n",
    "    for c in range(num_classes):\n",
    "        support = cm[c, :].sum()\n",
    "        correct = cm[c, c]\n",
    "        acc_c = correct / support if support > 0 else 0.0\n",
    "        per_class.append(acc_c)\n",
    "    return float(np.mean(per_class))\n",
    "\n",
    "def print_confusion(cm):\n",
    "    num_classes = cm.shape[0]\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "    for i in range(num_classes):\n",
    "        row = \" \".join(f\"{cm[i, j]:4d}\" for j in range(num_classes))\n",
    "        print(f\"class {i}: {row}\")\n",
    "\n",
    "def save_dataset(dataset, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(dataset, f)\n",
    "    print(f\"[dataset saved] {path.resolve()} (num_graphs={len(dataset)})\")\n",
    "\n",
    "def load_dataset(path: Path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        ds = pickle.load(f)\n",
    "    print(f\"[dataset loaded] {path.resolve()} (num_graphs={len(ds)})\")\n",
    "    return ds\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset generation\n",
    "# ---------------------------\n",
    "def make_synthetic_graph(n_min=10, n_max=30, p_range=(0.08, 0.2), q_range=(0.01, 0.08),\n",
    "                         feat_noise=0.2, weak_signal_scale=0.4, seed=None, shuffle_labels=False):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = int(rng.integers(n_min, n_max + 1))\n",
    "    n0 = N // 2\n",
    "\n",
    "    p = float(rng.uniform(*p_range))\n",
    "    q = float(rng.uniform(*q_range))\n",
    "    if p < q:\n",
    "        p, q = q, p\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(N))\n",
    "    comm = np.zeros(N, dtype=int)\n",
    "    comm[n0:] = 1\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            prob = p if comm[i] == comm[j] else q\n",
    "            if rng.random() < prob:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    edges = np.array(list(G.edges()), dtype=np.int64).T if G.number_of_edges() > 0 else np.zeros((2,0), dtype=np.int64)\n",
    "    edges_rev = edges[::-1]\n",
    "    edge_index = np.concatenate([edges, edges_rev], axis=1) if edges.shape[1] > 0 else edges\n",
    "\n",
    "    y = comm.astype(np.int64)\n",
    "    if shuffle_labels:\n",
    "        rng.shuffle(y)\n",
    "\n",
    "    degs = np.array([G.degree(i) for i in range(N)], dtype=np.float32)\n",
    "    deg_norm = (degs / max(1, N - 1)).astype(np.float32)\n",
    "    clustering = np.array(list(nx.clustering(G).values()), dtype=np.float32)\n",
    "    weak_signal = np.where(y == 1, +weak_signal_scale, -weak_signal_scale).astype(np.float32)\n",
    "\n",
    "    noise = rng.normal(0.0, feat_noise, size=(N, 3)).astype(np.float32)\n",
    "    X = np.stack([deg_norm, clustering, weak_signal], axis=1) + noise\n",
    "\n",
    "    return dict(edge_index=edge_index.astype(np.int64), X=X.astype(np.float32), y=y.astype(np.int64))\n",
    "\n",
    "def train_val_test_split_graphs(num_graphs, splits=(0.6, 0.2, 0.2), seed=0):\n",
    "    idx = np.arange(num_graphs)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "    n_train = int(splits[0] * num_graphs)\n",
    "    n_val = int(splits[1] * num_graphs)\n",
    "    train_idx = idx[:n_train]\n",
    "    val_idx = idx[n_train:n_train + n_val]\n",
    "    test_idx = idx[n_train + n_val:]\n",
    "    return train_idx, val_idx, test_idx\n",
    "\n",
    "# ---------------------------\n",
    "# EDU-QGC model\n",
    "# ---------------------------\n",
    "class EDUQGCNodeClassifier(nn.Module):\n",
    "    def __init__(self, n_nodes, in_feats=3, T=2, seed=0, use_gpu_qnode=True, use_feat_skip=True):\n",
    "        super().__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.T = T\n",
    "        self.use_feat_skip = use_feat_skip\n",
    "\n",
    "        # Parameter packing\n",
    "        self.enc_W = nn.Parameter(torch.randn(T, 2, in_feats) * 0.08)  # [T,2,F]\n",
    "        self.enc_b = nn.Parameter(torch.randn(T, 2) * 0.02)           # [T,2]\n",
    "\n",
    "        self.edge_phase  = nn.Parameter(torch.randn(T) * 0.08)\n",
    "        self.pre_theta   = nn.Parameter(torch.randn(T) * 0.08)\n",
    "        self.pre_psi     = nn.Parameter(torch.randn(T) * 0.08)\n",
    "        self.post_theta  = nn.Parameter(torch.randn(T) * 0.08)\n",
    "        self.post_psi    = nn.Parameter(torch.randn(T) * 0.08)\n",
    "\n",
    "        readin_dim = 1 + in_feats if use_feat_skip else 1\n",
    "        self.readout = nn.Linear(readin_dim, 2)\n",
    "\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        qdev_name = \"lightning.gpu\" if (use_gpu_qnode and use_cuda) else \"default.qubit\"\n",
    "        self.dev = qml.device(qdev_name, wires=n_nodes, shots=None)\n",
    "\n",
    "        @qml.qnode(self.dev, interface=\"torch\", diff_method=\"best\")\n",
    "        def circuit(edge_index, X, enc_W, enc_b,\n",
    "                    edge_phase, pre_theta, pre_psi, post_theta, post_psi):\n",
    "            # Loop layers\n",
    "            for t in range(self.T):\n",
    "                enc_out = X @ enc_W[t].T + enc_b[t]  # [N,2]\n",
    "                alphas = enc_out[:, 0]; betas = enc_out[:, 1]\n",
    "                for i in range(self.n_nodes):\n",
    "                    qml.RX(alphas[i], wires=i)\n",
    "                    qml.RY(betas[i], wires=i)\n",
    "\n",
    "                for i in range(self.n_nodes):\n",
    "                    qml.RZ(pre_psi[t], wires=i)\n",
    "                    qml.RX(pre_theta[t], wires=i)\n",
    "\n",
    "                E = edge_index.shape[1]\n",
    "                for e in range(E):\n",
    "                    u = int(edge_index[0, e].item()); v = int(edge_index[1, e].item())\n",
    "                    if u != v:\n",
    "                        qml.ControlledPhaseShift(edge_phase[t], wires=[u, v])\n",
    "\n",
    "                for i in range(self.n_nodes):\n",
    "                    qml.RZ(post_psi[t], wires=i)\n",
    "                    qml.RX(post_theta[t], wires=i)\n",
    "\n",
    "            return [qml.expval(qml.Z(i)) for i in range(self.n_nodes)]\n",
    "\n",
    "        self._circuit = circuit\n",
    "\n",
    "    def forward(self, edge_index_torch, x_torch):\n",
    "        model_device = next(self.parameters()).device\n",
    "        edge_index = edge_index_torch.to(model_device)\n",
    "        X = x_torch.to(model_device).float()\n",
    "\n",
    "        # Call QNode (PennyLane handles device movement if needed)\n",
    "        layer_out = self._circuit(\n",
    "            edge_index, X,\n",
    "            self.enc_W, self.enc_b,\n",
    "            self.edge_phase,\n",
    "            self.pre_theta, self.pre_psi,\n",
    "            self.post_theta, self.post_psi\n",
    "        )\n",
    "\n",
    "        expvals = torch.stack(layer_out, dim=0).float().to(model_device)\n",
    "        if expvals.dim() == 1:\n",
    "            expvals = expvals.unsqueeze(1)\n",
    "        elif expvals.dim() == 2 and expvals.shape[1] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            expvals = expvals.squeeze(-1).unsqueeze(1)\n",
    "\n",
    "        if self.use_feat_skip:\n",
    "            readin = torch.cat([expvals, X], dim=1)\n",
    "        else:\n",
    "            readin = expvals\n",
    "\n",
    "        logits = self.readout(readin)\n",
    "        return logits\n",
    "\n",
    "# ---------------------------\n",
    "# Train / Eval\n",
    "# ---------------------------\n",
    "def train_epoch(model, graphs, optimizer, device=\"cpu\"):\n",
    "    model.train()\n",
    "    total_loss = 0.0; total_nodes = 0\n",
    "    for g in graphs:\n",
    "        edge_index = torch.from_numpy(g[\"edge_index\"]).long().to(device)\n",
    "        X = torch.from_numpy(g[\"X\"]).float().to(device)\n",
    "        y = torch.from_numpy(g[\"y\"]).long().to(device)\n",
    "\n",
    "        logits = model(edge_index, X)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "        total_nodes += X.shape[0]\n",
    "    return total_loss / max(1, total_nodes)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, graphs, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    total_loss, total_nodes = 0.0, 0\n",
    "    for g in graphs:\n",
    "        edge_index = torch.from_numpy(g[\"edge_index\"]).long().to(device)\n",
    "        X = torch.from_numpy(g[\"X\"]).float().to(device)\n",
    "        y = torch.from_numpy(g[\"y\"]).long().to(device)\n",
    "\n",
    "        logits = model(edge_index, X)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        pred = logits.argmax(dim=1).cpu().numpy()\n",
    "        all_pred.extend(pred)\n",
    "        all_true.extend(list(y.cpu().numpy()))\n",
    "\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "        total_nodes += X.shape[0]\n",
    "\n",
    "    avg_loss = total_loss / max(1, total_nodes)\n",
    "    all_true = np.array(all_true); all_pred = np.array(all_pred)\n",
    "    mac_acc = macro_accuracy(all_true, all_pred, num_classes=2)\n",
    "    cm = confusion_matrix(all_true, all_pred, num_classes=2)\n",
    "    return avg_loss, mac_acc, cm, all_true, all_pred\n",
    "\n",
    "# ---------------------------\n",
    "# Experiment runner (full)\n",
    "# ---------------------------\n",
    "def run_experiment(\n",
    "    num_graphs=45,\n",
    "    splits=(0.6, 0.2, 0.2),\n",
    "    T=2,\n",
    "    epochs=50,\n",
    "    lr=0.03,\n",
    "    seed=42,\n",
    "    device=\"cuda\",\n",
    "    use_gpu_qnode=True,\n",
    "    save_dataset_path: str = \"./data/eduqgc_dataset_seed{seed}.pkl\",\n",
    "    plot_curves: bool = True\n",
    "):\n",
    "    # Reproducibility\n",
    "    set_global_determinism(seed)\n",
    "    print(\"[repro] seed:\", seed)\n",
    "    print(\"[repro] deterministic algos enabled:\", torch.are_deterministic_algorithms_enabled())\n",
    "    print(\"[repro] cudnn.deterministic:\", torch.backends.cudnn.deterministic)\n",
    "    print(\"[repro] cudnn.benchmark:\", torch.backends.cudnn.benchmark)\n",
    "    print(\"[repro] CUBLAS_WORKSPACE_CONFIG:\", os.environ.get(\"CUBLAS_WORKSPACE_CONFIG\"))\n",
    "\n",
    "    # Data\n",
    "    N_fixed = 20\n",
    "    ds_path = Path(save_dataset_path.format(seed=seed))\n",
    "    if ds_path.exists():\n",
    "        dataset = load_dataset(ds_path)\n",
    "    else:\n",
    "        dataset = []\n",
    "        for g in range(num_graphs):\n",
    "            graph = make_synthetic_graph(n_min=N_fixed, n_max=N_fixed, seed=seed + 2000 + g, shuffle_labels=False)\n",
    "            dataset.append(graph)\n",
    "        save_dataset(dataset, ds_path)\n",
    "\n",
    "    train_idx, val_idx, test_idx = train_val_test_split_graphs(num_graphs, splits=splits, seed=seed)\n",
    "    train_graphs = [dataset[i] for i in train_idx]\n",
    "    val_graphs = [dataset[i] for i in val_idx]\n",
    "    test_graphs = [dataset[i] for i in test_idx]\n",
    "\n",
    "    # Device selection\n",
    "    device = device if (device == \"cpu\" or torch.cuda.is_available()) else \"cpu\"\n",
    "    device = torch.device(device)\n",
    "    model = EDUQGCNodeClassifier(n_nodes=N_fixed, in_feats=3, T=T, seed=seed,\n",
    "                                use_gpu_qnode=use_gpu_qnode, use_feat_skip=True).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    best_val = (-1.0, None)\n",
    "    for ep in range(1, epochs + 1):\n",
    "        tr_loss = train_epoch(model, train_graphs, opt, device=device)\n",
    "        val_loss, val_mac, val_cm, _, _ = evaluate(model, val_graphs, device=device)\n",
    "\n",
    "        print(f\"Epoch {ep:03d} | train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | val_macro_acc={val_mac:.3f}\")\n",
    "\n",
    "        history[\"train_loss\"].append(tr_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_mac)\n",
    "\n",
    "        if val_mac > best_val[0]:\n",
    "            best_val = (val_mac, {k: v.detach().cpu().clone() for k, v in model.state_dict().items()})\n",
    "\n",
    "    # Load best\n",
    "    if best_val[1] is not None:\n",
    "        model.load_state_dict(best_val[1])\n",
    "\n",
    "    # Final eval\n",
    "    tr_loss, tr_mac, tr_cm, tr_y, tr_pred = evaluate(model, train_graphs, device=device)\n",
    "    va_loss, va_mac, va_cm, va_y, va_pred = evaluate(model, val_graphs, device=device)\n",
    "    te_loss, te_mac, te_cm, te_y, te_pred = evaluate(model, test_graphs, device=device)\n",
    "\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"- Train: macro-acc={tr_mac:.3f}, loss={tr_loss:.4f}\")\n",
    "    print_confusion(tr_cm)\n",
    "    print(f\"- Val:   macro-acc={va_mac:.3f}, loss={va_loss:.4f}\")\n",
    "    print_confusion(va_cm)\n",
    "    print(f\"- Test:  macro-acc={te_mac:.3f}, loss={te_loss:.4f}\")\n",
    "    print_confusion(te_cm)\n",
    "\n",
    "    # Save model + plots\n",
    "    out_dir = Path(\"outputs\")\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_path = out_dir / f\"eduqgc_model_seed{seed}_{ts}.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"[saved model] {model_path.resolve()}\")\n",
    "\n",
    "    plt_path = out_dir / f\"training_curves_seed{seed}_{ts}.png\"\n",
    "    if plot_curves:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "        ax[0].plot(history[\"train_loss\"], label=\"train loss\")\n",
    "        ax[0].plot(history[\"val_loss\"], label=\"val loss\")\n",
    "        ax[0].set_xlabel(\"epoch\"); ax[0].set_ylabel(\"loss\"); ax[0].legend(); ax[0].set_title(\"Loss\")\n",
    "\n",
    "        ax[1].plot(history[\"val_acc\"], label=\"val macro-acc\")\n",
    "        ax[1].set_xlabel(\"epoch\"); ax[1].set_ylabel(\"macro-accuracy\"); ax[1].legend(); ax[1].set_title(\"Validation Macro-Accuracy\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plt_path, dpi=200)\n",
    "        print(f\"[saved plot] {plt_path.resolve()}\")\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"splits\": (train_idx, val_idx, test_idx),\n",
    "        \"history\": history,\n",
    "        \"metrics\": {\n",
    "            \"train\": dict(loss=tr_loss, macro_acc=tr_mac, cm=tr_cm, y=tr_y, pred=tr_pred),\n",
    "            \"val\":   dict(loss=va_loss, macro_acc=va_mac, cm=va_cm, y=va_y, pred=va_pred),\n",
    "            \"test\":  dict(loss=te_loss, macro_acc=te_mac, cm=te_cm, y=te_y, pred=te_pred),\n",
    "        },\n",
    "        \"dataset_path\": str(ds_path.resolve()),\n",
    "        \"model_path\": str(model_path.resolve()),\n",
    "        \"plot_path\": str(plt_path.resolve()),\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    SEED = 42\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    USE_GPU_QNODE = True\n",
    "    NUM_GRAPHS = 45\n",
    "\n",
    "    results = run_experiment(\n",
    "        num_graphs=NUM_GRAPHS,\n",
    "        T=2,\n",
    "        epochs=50,\n",
    "        lr=0.03,\n",
    "        seed=SEED,\n",
    "        device=DEVICE,\n",
    "        use_gpu_qnode=USE_GPU_QNODE,\n",
    "        save_dataset_path=\"./data/eduqgc_dataset_seed{seed}.pkl\",\n",
    "        plot_curves=True\n",
    "    )\n",
    "    print(\"Done. Results summary keys:\", list(results.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374fe3e5",
   "metadata": {},
   "source": [
    "EDU-QGC with Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f0d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96620111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_synthetic_graph(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52806eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.zeros(10, dtype=np.int64)\n",
    "# y[len(y) // 2:] = 1\n",
    "# y\n",
    "\n",
    "# rng = np.random.default_rng(42)\n",
    "# rng.shuffle(y)\n",
    "\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979bda4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901df720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d01074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
